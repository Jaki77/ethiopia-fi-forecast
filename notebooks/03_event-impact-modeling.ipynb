{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1535ba1a",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb14374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# %%\n",
    "# Load the enriched dataset\n",
    "print(\"Loading enriched dataset...\")\n",
    "df = pd.read_csv('../data/processed/ethiopia_fi_enriched.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Load insights from Task 2\n",
    "key_insights = pd.read_csv('../data/processed/key_insights.csv')\n",
    "modeling_hypotheses = pd.read_csv('../data/processed/modeling_hypotheses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff93840",
   "metadata": {},
   "source": [
    "### 2. Understand the Impact Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80363ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate by record type\n",
    "observations = df[df['record_type'] == 'observation'].copy()\n",
    "events = df[df['record_type'] == 'event'].copy()\n",
    "impact_links = df[df['record_type'] == 'impact_link'].copy()\n",
    "targets = df[df['record_type'] == 'target'].copy()\n",
    "\n",
    "print(f\"Observations: {observations.shape[0]} records\")\n",
    "print(f\"Events: {events.shape[0]} records\")\n",
    "print(f\"Impact Links: {impact_links.shape[0]} records\")\n",
    "\n",
    "# Convert dates\n",
    "observations['observation_date'] = pd.to_datetime(observations['observation_date'], errors='coerce')\n",
    "events['event_date'] = pd.to_datetime(events['event_date'], errors='coerce')\n",
    "\n",
    "# %%\n",
    "# Join impact links with events to get full relationships\n",
    "impact_with_events = pd.merge(\n",
    "    impact_links,\n",
    "    events[['record_id', 'event_name', 'event_category', 'event_date', 'description']],\n",
    "    left_on='parent_id',\n",
    "    right_on='record_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Impact Links with Event Details:\")\n",
    "display(impact_with_events.head())\n",
    "\n",
    "# %%\n",
    "# Summary of impact relationships\n",
    "print(\"=\"*60)\n",
    "print(\"IMPACT RELATIONSHIPS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“Š Events by Category with Impact Counts:\")\n",
    "event_impact_summary = impact_with_events.groupby(['event_category', 'event_name']).agg({\n",
    "    'event_date': 'first',\n",
    "    'related_indicator': 'count',\n",
    "    'impact_direction': lambda x: ', '.join(x.unique()),\n",
    "    'impact_magnitude': lambda x: ', '.join(x.dropna().unique())\n",
    "}).reset_index()\n",
    "event_impact_summary = event_impact_summary.rename(columns={'related_indicator': 'impact_count'})\n",
    "display(event_impact_summary.sort_values(['event_category', 'event_date']))\n",
    "\n",
    "print(\"\\nðŸŽ¯ Indicators Most Affected by Events:\")\n",
    "indicator_impact_summary = impact_with_events.groupby(['pillar', 'related_indicator']).agg({\n",
    "    'event_name': 'count',\n",
    "    'impact_direction': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'mixed',\n",
    "    'impact_magnitude': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'mixed'\n",
    "}).reset_index()\n",
    "indicator_impact_summary = indicator_impact_summary.rename(columns={'event_name': 'event_count'})\n",
    "display(indicator_impact_summary.sort_values('event_count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2465be",
   "metadata": {},
   "source": [
    "### 3. Build Event-Indicator Association Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fe1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key indicators for forecasting\n",
    "key_indicators = [\n",
    "    'ACC_OWNERSHIP',           # Primary target: Account ownership\n",
    "    'ACC_MM_ACCOUNT',          # Mobile money accounts\n",
    "    'USG_DIGITAL_PAYMENT',     # Primary target: Digital payment usage\n",
    "    'USG_P2P_VOLUME',          # P2P transaction volume\n",
    "    'INF_AGENT_DENSITY',       # Infrastructure: Agent density\n",
    "    'ENB_MOBILE_INTERNET',     # Enabler: Mobile internet\n",
    "    'ENB_SMARTPHONE_PEN'       # Enabler: Smartphone penetration\n",
    "]\n",
    "\n",
    "# Get unique events\n",
    "unique_events = events['event_name'].unique()\n",
    "print(f\"Unique events: {len(unique_events)}\")\n",
    "print(f\"Key indicators: {len(key_indicators)}\")\n",
    "\n",
    "# %%\n",
    "# Initialize association matrix\n",
    "association_matrix = pd.DataFrame(\n",
    "    index=unique_events,\n",
    "    columns=key_indicators\n",
    ")\n",
    "\n",
    "# Also create matrices for direction, magnitude, and lag\n",
    "direction_matrix = pd.DataFrame(index=unique_events, columns=key_indicators)\n",
    "magnitude_matrix = pd.DataFrame(index=unique_events, columns=key_indicators)\n",
    "lag_matrix = pd.DataFrame(index=unique_events, columns=key_indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8049d",
   "metadata": {},
   "source": [
    "#### 3.1 Populate Matrices from Existing Impact Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2747af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert impact magnitude to numeric score\n",
    "def magnitude_to_score(magnitude):\n",
    "    \"\"\"Convert qualitative magnitude to numeric score (0-1).\"\"\"\n",
    "    if pd.isna(magnitude):\n",
    "        return 0\n",
    "    magnitude = str(magnitude).lower()\n",
    "    if 'very_high' in magnitude or 'vhigh' in magnitude:\n",
    "        return 0.9\n",
    "    elif 'high' in magnitude:\n",
    "        return 0.7\n",
    "    elif 'medium' in magnitude or 'moderate' in magnitude:\n",
    "        return 0.5\n",
    "    elif 'low' in magnitude:\n",
    "        return 0.3\n",
    "    elif 'very_low' in magnitude or 'vlow' in magnitude:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.5  # Default\n",
    "\n",
    "# Helper function to convert direction to sign\n",
    "def direction_to_sign(direction):\n",
    "    \"\"\"Convert direction to numeric sign.\"\"\"\n",
    "    if pd.isna(direction):\n",
    "        return 0\n",
    "    direction = str(direction).lower()\n",
    "    if 'positive' in direction or 'pos' in direction or 'increase' in direction:\n",
    "        return 1\n",
    "    elif 'negative' in direction or 'neg' in direction or 'decrease' in direction:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# %%\n",
    "# Populate matrices from existing impact links\n",
    "for _, link in impact_with_events.iterrows():\n",
    "    event_name = link['event_name']\n",
    "    indicator = link['related_indicator']\n",
    "    \n",
    "    if indicator in key_indicators and event_name in association_matrix.index:\n",
    "        # Calculate impact score\n",
    "        direction = direction_to_sign(link['impact_direction'])\n",
    "        magnitude = magnitude_to_score(link['impact_magnitude'])\n",
    "        impact_score = direction * magnitude\n",
    "        \n",
    "        # Update matrices\n",
    "        association_matrix.loc[event_name, indicator] = impact_score\n",
    "        direction_matrix.loc[event_name, indicator] = link['impact_direction']\n",
    "        magnitude_matrix.loc[event_name, indicator] = link['impact_magnitude']\n",
    "        lag_matrix.loc[event_name, indicator] = link.get('lag_months', 6)  # Default 6 months\n",
    "\n",
    "print(\"Association Matrix populated from existing impact links\")\n",
    "print(f\"Matrix shape: {association_matrix.shape}\")\n",
    "\n",
    "# Display sample of the matrix\n",
    "print(\"\\nAssociation Matrix (sample):\")\n",
    "display(association_matrix.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da56ef8",
   "metadata": {},
   "source": [
    "#### 3.2 Review Comparable Country Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d644547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comparable countries and their experiences\n",
    "comparable_countries = {\n",
    "    'Kenya': {\n",
    "        'm-pesa_launch': {\n",
    "            'mobile_money_adoption_increase': 25,  # Percentage points over 5 years\n",
    "            'lag_months': 12,\n",
    "            'applicable_events': ['Telebirr launch', 'M-Pesa entry']\n",
    "        },\n",
    "        'interoperability_regulation': {\n",
    "            'digital_payment_increase': 8,  # Percentage points in 18 months\n",
    "            'lag_months': 6,\n",
    "            'applicable_events': ['Interoperability regulation enacted']\n",
    "        }\n",
    "    },\n",
    "    'Tanzania': {\n",
    "        'mobile_money_regulation': {\n",
    "            'agent_density_increase': 15,  # Agents per 10k adults in 2 years\n",
    "            'lag_months': 24,\n",
    "            'applicable_events': ['Regulatory framework updates']\n",
    "        }\n",
    "    },\n",
    "    'Ghana': {\n",
    "        'mobile_money_interoperability': {\n",
    "            'transaction_volume_increase': 40,  # Percent increase in 1 year\n",
    "            'lag_months': 9,\n",
    "            'applicable_events': ['Interoperability regulation enacted']\n",
    "        }\n",
    "    },\n",
    "    'Rwanda': {\n",
    "        'digital_id_rollout': {\n",
    "            'account_ownership_increase': 7,  # Percentage points in 2 years\n",
    "            'lag_months': 18,\n",
    "            'applicable_events': ['Fayda Digital ID mass enrollment']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARABLE COUNTRY EVIDENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for country, experiences in comparable_countries.items():\n",
    "    print(f\"\\n{country}:\")\n",
    "    for exp_name, exp_data in experiences.items():\n",
    "        print(f\"  â€¢ {exp_name}: {exp_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f91dd1",
   "metadata": {},
   "source": [
    "#### 3.3 Estimate Missing Impacts Using Comparable Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event-indicator relationships based on comparable evidence and expert judgment\n",
    "event_impact_estimates = {\n",
    "    # Event: {indicator: (direction, magnitude_score, lag_months, confidence)}\n",
    "    'Telebirr launch': {\n",
    "        'ACC_MM_ACCOUNT': ('positive', 0.8, 12, 'high'),\n",
    "        'USG_DIGITAL_PAYMENT': ('positive', 0.6, 6, 'high'),\n",
    "        'USG_P2P_VOLUME': ('positive', 0.7, 3, 'medium'),\n",
    "        'ACC_OWNERSHIP': ('positive', 0.4, 18, 'medium')\n",
    "    },\n",
    "    'M-Pesa entry': {\n",
    "        'ACC_MM_ACCOUNT': ('positive', 0.6, 6, 'high'),\n",
    "        'USG_DIGITAL_PAYMENT': ('positive', 0.5, 3, 'high'),\n",
    "        'USG_P2P_VOLUME': ('positive', 0.6, 3, 'medium'),\n",
    "        'INF_AGENT_DENSITY': ('positive', 0.4, 12, 'medium')\n",
    "    },\n",
    "    'Interoperability regulation enacted': {\n",
    "        'USG_DIGITAL_PAYMENT': ('positive', 0.7, 6, 'medium'),\n",
    "        'USG_P2P_VOLUME': ('positive', 0.8, 3, 'medium'),\n",
    "        'ACC_OWNERSHIP': ('positive', 0.3, 12, 'low')\n",
    "    },\n",
    "    'Fayda Digital ID mass enrollment': {\n",
    "        'ACC_OWNERSHIP': ('positive', 0.5, 18, 'medium'),\n",
    "        'ACC_MM_ACCOUNT': ('positive', 0.4, 12, 'medium'),\n",
    "        'USG_DIGITAL_PAYMENT': ('positive', 0.3, 24, 'low')\n",
    "    },\n",
    "    'National QR code merchant rollout': {\n",
    "        'USG_DIGITAL_PAYMENT': ('positive', 0.6, 3, 'medium'),\n",
    "        'USG_P2P_VOLUME': ('positive', 0.4, 6, 'medium')\n",
    "    },\n",
    "    'Safaricom market entry': {\n",
    "        'ACC_MM_ACCOUNT': ('positive', 0.3, 12, 'medium'),\n",
    "        'INF_AGENT_DENSITY': ('positive', 0.5, 18, 'medium')\n",
    "    }\n",
    "}\n",
    "\n",
    "# %%\n",
    "# Update matrices with estimated impacts\n",
    "for event_name, impacts in event_impact_estimates.items():\n",
    "    if event_name in association_matrix.index:\n",
    "        for indicator, (direction_str, magnitude_score, lag, confidence) in impacts.items():\n",
    "            if indicator in association_matrix.columns:\n",
    "                direction = direction_to_sign(direction_str)\n",
    "                impact_score = direction * magnitude_score\n",
    "                \n",
    "                # Only update if not already populated from impact links\n",
    "                if pd.isna(association_matrix.loc[event_name, indicator]):\n",
    "                    association_matrix.loc[event_name, indicator] = impact_score\n",
    "                    direction_matrix.loc[event_name, indicator] = direction_str\n",
    "                    magnitude_matrix.loc[event_name, indicator] = f\"{magnitude_score:.1f}\"\n",
    "                    lag_matrix.loc[event_name, indicator] = lag\n",
    "\n",
    "print(\"Matrices updated with estimated impacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b115e8",
   "metadata": {},
   "source": [
    "#### 3.4 Fill Remaining Gaps with Default/Neutral Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a95e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining NaN values with 0 (no impact)\n",
    "association_matrix = association_matrix.fillna(0)\n",
    "direction_matrix = direction_matrix.fillna('neutral')\n",
    "magnitude_matrix = magnitude_matrix.fillna('0.0')\n",
    "lag_matrix = lag_matrix.fillna(0)\n",
    "\n",
    "print(\"Association Matrix (complete):\")\n",
    "display(association_matrix)\n",
    "\n",
    "# %%\n",
    "# Convert association matrix to numeric for calculations\n",
    "association_matrix_numeric = association_matrix.astype(float)\n",
    "\n",
    "# Calculate event strength (sum of absolute impacts)\n",
    "event_strength = association_matrix_numeric.abs().sum(axis=1).sort_values(ascending=False)\n",
    "print(\"\\nðŸ“Š Event Strength (sum of absolute impacts):\")\n",
    "print(event_strength)\n",
    "\n",
    "# Calculate indicator sensitivity (sum of absolute impacts)\n",
    "indicator_sensitivity = association_matrix_numeric.abs().sum(axis=0).sort_values(ascending=False)\n",
    "print(\"\\nðŸŽ¯ Indicator Sensitivity (sum of absolute impacts):\")\n",
    "print(indicator_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8474ca3",
   "metadata": {},
   "source": [
    "### 4. Visualize the Association Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap visualization\n",
    "plt.figure(figsize=(14, 10))\n",
    "mask = association_matrix_numeric == 0\n",
    "sns.heatmap(association_matrix_numeric, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            annot=True, \n",
    "            fmt='.2f',\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={'label': 'Impact Score (-1 to +1)'},\n",
    "            mask=mask)\n",
    "plt.title('Event-Impact Association Matrix\\n(Impact Score: -1 = Strong Negative, +1 = Strong Positive)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Indicators')\n",
    "plt.ylabel('Events')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/event_impact_association_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Interactive heatmap with Plotly\n",
    "fig = px.imshow(association_matrix_numeric,\n",
    "                labels=dict(x=\"Indicator\", y=\"Event\", color=\"Impact Score\"),\n",
    "                x=association_matrix_numeric.columns,\n",
    "                y=association_matrix_numeric.index,\n",
    "                color_continuous_scale='RdBu',\n",
    "                color_continuous_midpoint=0,\n",
    "                title=\"Event-Impact Association Matrix (Interactive)\")\n",
    "fig.update_layout(height=600)\n",
    "fig.write_html('../data/processed/event_impact_matrix_interactive.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee1a32",
   "metadata": {},
   "source": [
    "### 5. Test Model Against Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d1510",
   "metadata": {},
   "source": [
    "#### 5.1 Telebirr Launch Impact Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f72a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"HISTORICAL VALIDATION: TELEBIRR LAUNCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get Telebirr launch date\n",
    "telebirr_date = pd.Timestamp('2021-05-01')\n",
    "\n",
    "# Get mobile money account data before and after Telebirr\n",
    "mm_before = observations[\n",
    "    (observations['indicator_code'] == 'ACC_MM_ACCOUNT') &\n",
    "    (observations['observation_date'] < telebirr_date)\n",
    "].sort_values('observation_date')\n",
    "\n",
    "mm_after = observations[\n",
    "    (observations['indicator_code'] == 'ACC_MM_ACCOUNT') &\n",
    "    (observations['observation_date'] > telebirr_date)\n",
    "].sort_values('observation_date')\n",
    "\n",
    "# Calculate actual impact\n",
    "if not mm_before.empty and not mm_after.empty:\n",
    "    mm_pre = mm_before.iloc[-1]['value_numeric']\n",
    "    mm_post_1yr = mm_after[mm_after['observation_date'] <= telebirr_date + pd.DateOffset(years=1)]\n",
    "    mm_post_3yr = mm_after[mm_after['observation_date'] <= telebirr_date + pd.DateOffset(years=3)]\n",
    "    \n",
    "    if not mm_post_1yr.empty:\n",
    "        mm_1yr = mm_post_1yr.iloc[-1]['value_numeric']\n",
    "    else:\n",
    "        mm_1yr = None\n",
    "    \n",
    "    if not mm_post_3yr.empty:\n",
    "        mm_3yr = mm_post_3yr.iloc[-1]['value_numeric']\n",
    "    else:\n",
    "        mm_3yr = None\n",
    "    \n",
    "    print(f\"\\nðŸ“± Mobile Money Accounts (ACC_MM_ACCOUNT):\")\n",
    "    print(f\"   Before Telebirr launch: {mm_pre}%\")\n",
    "    if mm_1yr:\n",
    "        print(f\"   ~1 year after launch: {mm_1yr}%\")\n",
    "        print(f\"   Change: +{mm_1yr - mm_pre:.2f}pp\")\n",
    "    if mm_3yr:\n",
    "        print(f\"   ~3 years after launch: {mm_3yr}%\")\n",
    "        print(f\"   Change: +{mm_3yr - mm_pre:.2f}pp\")\n",
    "    \n",
    "    # Compare with model prediction\n",
    "    model_impact = association_matrix_numeric.loc['Telebirr launch', 'ACC_MM_ACCOUNT']\n",
    "    print(f\"\\nðŸ“Š Model Prediction for ACC_MM_ACCOUNT:\")\n",
    "    print(f\"   Impact score: {model_impact:.2f}\")\n",
    "    print(f\"   Direction: {direction_matrix.loc['Telebirr launch', 'ACC_MM_ACCOUNT']}\")\n",
    "    print(f\"   Magnitude: {magnitude_matrix.loc['Telebirr launch', 'ACC_MM_ACCOUNT']}\")\n",
    "    print(f\"   Lag: {lag_matrix.loc['Telebirr launch', 'ACC_MM_ACCOUNT']} months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a1ee6",
   "metadata": {},
   "source": [
    "#### 5.2 M-Pesa Entry Impact Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HISTORICAL VALIDATION: M-PESA ENTRY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get M-Pesa entry date\n",
    "mpesa_date = pd.Timestamp('2023-08-01')\n",
    "\n",
    "# Get data before and after M-Pesa entry\n",
    "# Since we don't have 2025 data yet, we'll use the latest available\n",
    "mpesa_before = observations[\n",
    "    (observations['observation_date'] < mpesa_date)\n",
    "].sort_values('observation_date')\n",
    "\n",
    "mpesa_after = observations[\n",
    "    (observations['observation_date'] > mpesa_date)\n",
    "].sort_values('observation_date')\n",
    "\n",
    "print(f\"\\nðŸ“… Data Availability:\")\n",
    "print(f\"   Latest data before M-Pesa: {mpesa_before['observation_date'].max().strftime('%Y-%m') if not mpesa_before.empty else 'N/A'}\")\n",
    "print(f\"   Earliest data after M-Pesa: {mpesa_after['observation_date'].min().strftime('%Y-%m') if not mpesa_after.empty else 'N/A'}\")\n",
    "\n",
    "# Get specific indicators\n",
    "for indicator in ['ACC_MM_ACCOUNT', 'USG_DIGITAL_PAYMENT']:\n",
    "    ind_before = mpesa_before[mpesa_before['indicator_code'] == indicator]\n",
    "    ind_after = mpesa_after[mpesa_after['indicator_code'] == indicator]\n",
    "    \n",
    "    if not ind_before.empty and not ind_after.empty:\n",
    "        before_val = ind_before.iloc[-1]['value_numeric']\n",
    "        after_val = ind_after.iloc[0]['value_numeric']\n",
    "        change = after_val - before_val\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ {indicator}:\")\n",
    "        print(f\"   Before M-Pesa: {before_val}%\")\n",
    "        print(f\"   After M-Pesa: {after_val}%\")\n",
    "        print(f\"   Change: {change:+.2f}pp\")\n",
    "        \n",
    "        # Compare with model\n",
    "        model_impact = association_matrix_numeric.loc['M-Pesa entry', indicator]\n",
    "        print(f\"   Model impact score: {model_impact:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4777ab5",
   "metadata": {},
   "source": [
    "#### 5.3 Statistical Analysis of Event Impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create event impact timeline for visualization\n",
    "event_impacts = []\n",
    "\n",
    "for event_name in association_matrix_numeric.index:\n",
    "    event_date = events[events['event_name'] == event_name]['event_date']\n",
    "    if not event_date.empty:\n",
    "        event_date = event_date.iloc[0]\n",
    "        \n",
    "        # Get indicators affected by this event\n",
    "        affected_indicators = association_matrix_numeric.columns[\n",
    "            association_matrix_numeric.loc[event_name].abs() > 0\n",
    "        ]\n",
    "        \n",
    "        for indicator in affected_indicators:\n",
    "            impact_score = association_matrix_numeric.loc[event_name, indicator]\n",
    "            if impact_score != 0:\n",
    "                event_impacts.append({\n",
    "                    'event': event_name,\n",
    "                    'event_date': event_date,\n",
    "                    'indicator': indicator,\n",
    "                    'impact_score': impact_score,\n",
    "                    'direction': direction_matrix.loc[event_name, indicator],\n",
    "                    'magnitude': magnitude_matrix.loc[event_name, indicator],\n",
    "                    'lag_months': lag_matrix.loc[event_name, indicator]\n",
    "                })\n",
    "\n",
    "event_impacts_df = pd.DataFrame(event_impacts)\n",
    "print(f\"\\nTotal event-impact relationships modeled: {len(event_impacts_df)}\")\n",
    "\n",
    "# %%\n",
    "# Visualize event impacts over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Impact distribution by event category\n",
    "event_categories = events.set_index('event_name')['event_category']\n",
    "event_impacts_df['event_category'] = event_impacts_df['event'].map(event_categories)\n",
    "\n",
    "if 'event_category' in event_impacts_df.columns:\n",
    "    category_impact = event_impacts_df.groupby('event_category')['impact_score'].agg(['mean', 'count', 'std'])\n",
    "    axes[0,0].bar(category_impact.index, category_impact['mean'].abs(), \n",
    "                  color=['green', 'blue', 'orange', 'red'][:len(category_impact)])\n",
    "    axes[0,0].set_title('Average Impact Strength by Event Category', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('Average |Impact Score|')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (idx, row) in enumerate(category_impact.iterrows()):\n",
    "        axes[0,0].text(i, row['mean'].abs() + 0.02, f\"n={int(row['count'])}\", \n",
    "                      ha='center', fontsize=9)\n",
    "\n",
    "# 2. Impact distribution by pillar\n",
    "pillar_mapping = {\n",
    "    'ACC': 'Access',\n",
    "    'USG': 'Usage',\n",
    "    'INF': 'Infrastructure',\n",
    "    'ENB': 'Enablers'\n",
    "}\n",
    "event_impacts_df['pillar'] = event_impacts_df['indicator'].apply(\n",
    "    lambda x: x.split('_')[0] if '_' in str(x) else 'OTHER'\n",
    ")\n",
    "event_impacts_df['pillar_label'] = event_impacts_df['pillar'].map(pillar_mapping).fillna('Other')\n",
    "\n",
    "pillar_impact = event_impacts_df.groupby('pillar_label')['impact_score'].agg(['mean', 'count'])\n",
    "axes[0,1].bar(pillar_impact.index, pillar_impact['mean'].abs(), \n",
    "              color=['darkblue', 'darkgreen', 'darkred', 'darkorange'][:len(pillar_impact)])\n",
    "axes[0,1].set_title('Average Impact Strength by Pillar', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Average |Impact Score|')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Lag distribution\n",
    "axes[1,0].hist(event_impacts_df['lag_months'].dropna(), bins=10, \n",
    "               color='purple', alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_title('Distribution of Impact Lag Times', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Lag (months)')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].axvline(event_impacts_df['lag_months'].median(), color='red', \n",
    "                 linestyle='--', label=f'Median: {event_impacts_df[\"lag_months\"].median():.0f} months')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 4. Impact score distribution\n",
    "axes[1,1].hist(event_impacts_df['impact_score'], bins=20, \n",
    "               color='teal', alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_title('Distribution of Impact Scores', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Impact Score')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "axes[1,1].axvline(0, color='red', linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/event_impact_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b1378",
   "metadata": {},
   "source": [
    "### 6. Refine Impact Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"REFINING IMPACT ESTIMATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Based on historical validation, adjust estimates\n",
    "adjustments = []\n",
    "\n",
    "# 1. Telebirr impact adjustment based on actual data\n",
    "if 'mm_pre' in locals() and 'mm_3yr' in locals():\n",
    "    actual_telebirr_impact = (mm_3yr - mm_pre) / 100  # Convert pp to proportion\n",
    "    model_telebirr_impact = association_matrix_numeric.loc['Telebirr launch', 'ACC_MM_ACCOUNT']\n",
    "    \n",
    "    if abs(actual_telebirr_impact - model_telebirr_impact) > 0.1:\n",
    "        adjustments.append({\n",
    "            'event': 'Telebirr launch',\n",
    "            'indicator': 'ACC_MM_ACCOUNT',\n",
    "            'old_score': model_telebirr_impact,\n",
    "            'new_score': actual_telebirr_impact,\n",
    "            'reason': f'Actual growth: +{mm_3yr - mm_pre:.1f}pp over 3 years'\n",
    "        })\n",
    "        # Update the matrix\n",
    "        association_matrix_numeric.loc['Telebirr launch', 'ACC_MM_ACCOUNT'] = actual_telebirr_impact\n",
    "\n",
    "# 2. Adjust based on comparable country evidence\n",
    "for event_name in ['Interoperability regulation enacted', 'Fayda Digital ID mass enrollment']:\n",
    "    if event_name in association_matrix_numeric.index:\n",
    "        # Increase impact on digital payments based on Kenya evidence\n",
    "        if 'USG_DIGITAL_PAYMENT' in association_matrix_numeric.columns:\n",
    "            current_impact = association_matrix_numeric.loc[event_name, 'USG_DIGITAL_PAYMENT']\n",
    "            if abs(current_impact) < 0.5:  # If impact is relatively low\n",
    "                new_impact = min(0.7, current_impact + 0.2)  # Increase by 0.2, cap at 0.7\n",
    "                adjustments.append({\n",
    "                    'event': event_name,\n",
    "                    'indicator': 'USG_DIGITAL_PAYMENT',\n",
    "                    'old_score': current_impact,\n",
    "                    'new_score': new_impact,\n",
    "                    'reason': 'Based on Kenya interoperability evidence (+8-12pp impact)'\n",
    "                })\n",
    "                association_matrix_numeric.loc[event_name, 'USG_DIGITAL_PAYMENT'] = new_impact\n",
    "\n",
    "print(f\"\\nMade {len(adjustments)} adjustments based on validation:\")\n",
    "\n",
    "if adjustments:\n",
    "    adjustments_df = pd.DataFrame(adjustments)\n",
    "    display(adjustments_df)\n",
    "else:\n",
    "    print(\"No significant adjustments needed based on current validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2db72",
   "metadata": {},
   "source": [
    "### 7. Document Confidence Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confidence matrix\n",
    "confidence_matrix = pd.DataFrame(index=association_matrix_numeric.index, \n",
    "                                 columns=association_matrix_numeric.columns)\n",
    "\n",
    "# Assign confidence based on:\n",
    "# 1. Existence of historical data for validation\n",
    "# 2. Comparable country evidence\n",
    "# 3. Expert judgment\n",
    "\n",
    "confidence_criteria = {\n",
    "    'high': [\n",
    "        ('Telebirr launch', 'ACC_MM_ACCOUNT'),\n",
    "        ('M-Pesa entry', 'ACC_MM_ACCOUNT'),\n",
    "        ('Telebirr launch', 'USG_DIGITAL_PAYMENT')\n",
    "    ],\n",
    "    'medium': [\n",
    "        ('Interoperability regulation enacted', 'USG_DIGITAL_PAYMENT'),\n",
    "        ('Fayda Digital ID mass enrollment', 'ACC_OWNERSHIP'),\n",
    "        ('National QR code merchant rollout', 'USG_DIGITAL_PAYMENT')\n",
    "    ],\n",
    "    'low': [\n",
    "        ('Fayda Digital ID mass enrollment', 'USG_DIGITAL_PAYMENT'),\n",
    "        ('Interoperability regulation enacted', 'ACC_OWNERSHIP')\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Initialize all as medium confidence\n",
    "confidence_matrix[:] = 'medium'\n",
    "\n",
    "# Apply specific confidence levels\n",
    "for confidence_level, pairs in confidence_criteria.items():\n",
    "    for event, indicator in pairs:\n",
    "        if event in confidence_matrix.index and indicator in confidence_matrix.columns:\n",
    "            confidence_matrix.loc[event, indicator] = confidence_level\n",
    "\n",
    "print(\"Confidence Matrix (sample):\")\n",
    "display(confidence_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b7cb3",
   "metadata": {},
   "source": [
    "### 8. Create Impact Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f35d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_event_impact(event_name, indicator, months_after_event):\n",
    "    \"\"\"\n",
    "    Calculate the impact of an event on an indicator at a specific time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    event_name : str\n",
    "        Name of the event\n",
    "    indicator : str\n",
    "        Indicator code\n",
    "    months_after_event : int\n",
    "        Number of months after the event\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    impact : float\n",
    "        Impact score (0 to 1 for positive, -1 to 0 for negative)\n",
    "    \"\"\"\n",
    "    if event_name not in association_matrix_numeric.index or indicator not in association_matrix_numeric.columns:\n",
    "        return 0.0\n",
    "    \n",
    "    base_impact = association_matrix_numeric.loc[event_name, indicator]\n",
    "    lag_months = lag_matrix.loc[event_name, indicator]\n",
    "    \n",
    "    if pd.isna(lag_months) or base_impact == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Simple sigmoid function for impact buildup over time\n",
    "    if months_after_event <= 0:\n",
    "        return 0.0\n",
    "    elif months_after_event < lag_months:\n",
    "        # Building up to full impact\n",
    "        buildup_factor = months_after_event / lag_months\n",
    "        return base_impact * buildup_factor\n",
    "    else:\n",
    "        # Full impact achieved\n",
    "        return base_impact\n",
    "\n",
    "def calculate_combined_impact(events, indicator, date):\n",
    "    \"\"\"\n",
    "    Calculate combined impact of multiple events on an indicator at a specific date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    events : list of tuples\n",
    "        List of (event_name, event_date) tuples\n",
    "    indicator : str\n",
    "        Indicator code\n",
    "    date : datetime\n",
    "        Date for which to calculate impact\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    total_impact : float\n",
    "        Sum of individual event impacts\n",
    "    \"\"\"\n",
    "    total_impact = 0.0\n",
    "    \n",
    "    for event_name, event_date in events:\n",
    "        if pd.isna(event_date):\n",
    "            continue\n",
    "            \n",
    "        months_after = (date.year - event_date.year) * 12 + (date.month - event_date.month)\n",
    "        impact = calculate_event_impact(event_name, indicator, months_after)\n",
    "        total_impact += impact\n",
    "    \n",
    "    return total_impact\n",
    "\n",
    "def forecast_with_events(base_forecast, events, indicator, forecast_dates):\n",
    "    \"\"\"\n",
    "    Generate forecast incorporating event impacts.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_forecast : pd.Series\n",
    "        Baseline forecast without events\n",
    "    events : list of tuples\n",
    "        List of (event_name, event_date) tuples\n",
    "    indicator : str\n",
    "        Indicator code\n",
    "    forecast_dates : pd.DatetimeIndex\n",
    "        Dates to forecast\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    event_adjusted_forecast : pd.Series\n",
    "        Forecast with event impacts incorporated\n",
    "    \"\"\"\n",
    "    event_impacts = pd.Series(index=forecast_dates, dtype=float)\n",
    "    \n",
    "    for date in forecast_dates:\n",
    "        impact = calculate_combined_impact(events, indicator, date)\n",
    "        event_impacts[date] = impact\n",
    "    \n",
    "    # Convert impact scores to percentage points\n",
    "    # Assuming 1.0 impact score = 10 percentage points\n",
    "    impact_pp = event_impacts * 10\n",
    "    \n",
    "    # Add to base forecast\n",
    "    adjusted_forecast = base_forecast + impact_pp\n",
    "    \n",
    "    return adjusted_forecast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95d897",
   "metadata": {},
   "source": [
    "### 9. Test the Impact Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b96e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MODEL TESTING WITH HISTORICAL DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test: What would our model have predicted for Telebirr impact?\n",
    "test_event = [('Telebirr launch', pd.Timestamp('2021-05-01'))]\n",
    "test_dates = pd.date_range(start='2021-05-01', end='2024-12-01', freq='MS')\n",
    "\n",
    "# Create a simple baseline (linear growth from pre-Telebirr level)\n",
    "if 'mm_pre' in locals():\n",
    "    baseline = pd.Series(index=test_dates, dtype=float)\n",
    "    # Simple linear interpolation\n",
    "    for i, date in enumerate(test_dates):\n",
    "        months_from_start = i\n",
    "        baseline[date] = mm_pre + (months_from_start / 36) * (mm_3yr - mm_pre)  # Over 3 years\n",
    "    \n",
    "    # Apply event impact model\n",
    "    model_forecast = forecast_with_events(baseline, test_event, 'ACC_MM_ACCOUNT', test_dates)\n",
    "    \n",
    "    # Get actual data points\n",
    "    actual_dates = []\n",
    "    actual_values = []\n",
    "    for _, row in observations[observations['indicator_code'] == 'ACC_MM_ACCOUNT'].iterrows():\n",
    "        actual_dates.append(row['observation_date'])\n",
    "        actual_values.append(row['value_numeric'])\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot baseline and model forecast\n",
    "    ax.plot(baseline.index, baseline.values, 'b--', label='Baseline (no Telebirr)', alpha=0.7)\n",
    "    ax.plot(model_forecast.index, model_forecast.values, 'g-', label='Model with Telebirr impact', linewidth=2)\n",
    "    \n",
    "    # Plot actual data points\n",
    "    ax.scatter(actual_dates, actual_values, color='red', s=100, label='Actual data', zorder=5)\n",
    "    \n",
    "    ax.set_title('Model Test: Telebirr Impact on Mobile Money Accounts', fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Mobile Money Accounts (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/model_test_telebirr.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate model error\n",
    "    if actual_values and len(actual_values) >= 2:\n",
    "        # Compare last actual with model prediction at that time\n",
    "        last_actual_date = actual_dates[-1]\n",
    "        last_actual_value = actual_values[-1]\n",
    "        \n",
    "        if last_actual_date in model_forecast.index:\n",
    "            model_prediction = model_forecast[last_actual_date]\n",
    "            error = abs(model_prediction - last_actual_value)\n",
    "            error_pct = (error / last_actual_value) * 100\n",
    "            \n",
    "            print(f\"\\nðŸ“Š Model Performance:\")\n",
    "            print(f\"   Actual (2024): {last_actual_value:.2f}%\")\n",
    "            print(f\"   Model prediction: {model_prediction:.2f}%\")\n",
    "            print(f\"   Absolute error: {error:.2f}pp\")\n",
    "            print(f\"   Relative error: {error_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c148504",
   "metadata": {},
   "source": [
    "### 10. Document Methodology and Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"METHODOLOGY DOCUMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "methodology = {\n",
    "    'impact_scoring': {\n",
    "        'description': 'Impact scores range from -1 (strong negative) to +1 (strong positive)',\n",
    "        'magnitude_mapping': {\n",
    "            'very_high': 0.9,\n",
    "            'high': 0.7,\n",
    "            'medium': 0.5,\n",
    "            'low': 0.3,\n",
    "            'very_low': 0.1\n",
    "        },\n",
    "        'direction_mapping': {\n",
    "            'positive': 1,\n",
    "            'negative': -1,\n",
    "            'neutral': 0\n",
    "        }\n",
    "    },\n",
    "    'temporal_dynamics': {\n",
    "        'impact_buildup': 'Linear buildup to full impact over lag period',\n",
    "        'lag_periods': 'Based on event type: product launches (3-12 months), policies (6-24 months)',\n",
    "        'persistence': 'Assumed permanent impact once fully realized'\n",
    "    },\n",
    "    'combined_effects': {\n",
    "        'assumption': 'Additive combination of individual event impacts',\n",
    "        'limitation': 'Does not model interaction/synergy effects between events',\n",
    "        'note': 'Conservative approach to avoid overestimation'\n",
    "    },\n",
    "    'data_sources': {\n",
    "        'historical_validation': 'Used actual Ethiopian data where available (Telebirr, M-Pesa)',\n",
    "        'comparable_evidence': 'Kenya (M-Pesa, interoperability), Rwanda (digital ID), Ghana (interoperability)',\n",
    "        'expert_judgment': 'Applied for events without direct precedents in Ethiopia'\n",
    "    },\n",
    "    'uncertainty_handling': {\n",
    "        'confidence_levels': 'High/Medium/Low based on evidence quality',\n",
    "        'sensitivity': 'Impact scores represent central estimates',\n",
    "        'recommendation': 'Use Â±30% range for low-confidence estimates in scenarios'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“‹ Methodology Summary:\")\n",
    "for category, details in methodology.items():\n",
    "    print(f\"\\n{category.upper().replace('_', ' ')}:\")\n",
    "    if isinstance(details, dict):\n",
    "        for key, value in details.items():\n",
    "            print(f\"  â€¢ {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {details}\")\n",
    "\n",
    "# Save methodology documentation\n",
    "import json\n",
    "with open('../data/processed/impact_modeling_methodology.json', 'w') as f:\n",
    "    json.dump(methodology, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Methodology saved to '../data/processed/impact_modeling_methodology.json'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a64899",
   "metadata": {},
   "source": [
    "### 11. Limitations and Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MODEL LIMITATIONS AND UNCERTAINTIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "limitations = [\n",
    "    {\n",
    "        'limitation': 'Limited Ethiopian historical data',\n",
    "        'description': 'Few events with pre/post data for validation in Ethiopia',\n",
    "        'mitigation': 'Relied on comparable country evidence and expert judgment'\n",
    "    },\n",
    "    {\n",
    "        'limitation': 'Additive impact assumption',\n",
    "        'description': 'Assumes events have independent, additive effects (no interactions)',\n",
    "        'mitigation': 'Conservative estimates; future enhancement: interaction terms'\n",
    "    },\n",
    "    {\n",
    "        'limitation': 'Simplified temporal dynamics',\n",
    "        'description': 'Linear buildup of impacts, instant persistence after lag',\n",
    "        'mitigation': 'Adequate for annual forecasts; refine for monthly precision'\n",
    "    },\n",
    "    {\n",
    "        'limitation': 'Qualitative to quantitative conversion',\n",
    "        'description': 'Converting qualitative impact estimates to numeric scores involves judgment',\n",
    "        'mitigation': 'Used consistent mapping scheme; document assumptions'\n",
    "    },\n",
    "    {\n",
    "        'limitation': 'Static impact magnitudes',\n",
    "        'description': 'Impact magnitudes don\\'t vary with economic conditions or saturation',\n",
    "        'mitigation': 'Scenario analysis will address different conditions'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nâš ï¸  Key Limitations:\")\n",
    "for i, limit in enumerate(limitations, 1):\n",
    "    print(f\"\\n{i}. {limit['limitation']}\")\n",
    "    print(f\"   Description: {limit['description']}\")\n",
    "    print(f\"   Mitigation: {limit['mitigation']}\")\n",
    "\n",
    "# Save limitations\n",
    "limitations_df = pd.DataFrame(limitations)\n",
    "limitations_df.to_csv('../data/processed/impact_modeling_limitations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a8125",
   "metadata": {},
   "source": [
    "### 12. Task 3 Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TASK 3 COMPLETION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save all matrices\n",
    "output_files = []\n",
    "\n",
    "# Save association matrix\n",
    "association_matrix_path = '../data/processed/event_indicator_association_matrix.csv'\n",
    "association_matrix_numeric.to_csv(association_matrix_path)\n",
    "output_files.append(association_matrix_path)\n",
    "print(f\"âœ“ Association matrix saved: {association_matrix_path}\")\n",
    "\n",
    "# Save direction matrix\n",
    "direction_matrix_path = '../data/processed/event_impact_directions.csv'\n",
    "direction_matrix.to_csv(direction_matrix_path)\n",
    "output_files.append(direction_matrix_path)\n",
    "\n",
    "# Save magnitude matrix\n",
    "magnitude_matrix_path = '../data/processed/event_impact_magnitudes.csv'\n",
    "magnitude_matrix.to_csv(magnitude_matrix_path)\n",
    "output_files.append(magnitude_matrix_path)\n",
    "\n",
    "# Save lag matrix\n",
    "lag_matrix_path = '../data/processed/event_impact_lags.csv'\n",
    "lag_matrix.to_csv(lag_matrix_path)\n",
    "output_files.append(lag_matrix_path)\n",
    "\n",
    "# Save confidence matrix\n",
    "confidence_matrix_path = '../data/processed/event_impact_confidence.csv'\n",
    "confidence_matrix.to_csv(confidence_matrix_path)\n",
    "output_files.append(confidence_matrix_path)\n",
    "\n",
    "# Save all event impacts\n",
    "event_impacts_df_path = '../data/processed/all_event_impacts.csv'\n",
    "event_impacts_df.to_csv(event_impacts_df_path, index=False)\n",
    "output_files.append(event_impacts_df_path)\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Statistics:\")\n",
    "print(f\"   Events modeled: {len(association_matrix_numeric)}\")\n",
    "print(f\"   Indicators covered: {len(association_matrix_numeric.columns)}\")\n",
    "print(f\"   Total event-indicator relationships: {len(event_impacts_df)}\")\n",
    "print(f\"   Average impact strength: {event_impacts_df['impact_score'].abs().mean():.3f}\")\n",
    "print(f\"   Median lag time: {event_impacts_df['lag_months'].median():.0f} months\")\n",
    "\n",
    "print(f\"\\nâœ… Output files generated: {len(output_files)} files\")\n",
    "for file in output_files[:3]:  # Show first 3\n",
    "    print(f\"  â€¢ {file.split('/')[-1]}\")\n",
    "if len(output_files) > 3:\n",
    "    print(f\"  â€¢ ... and {len(output_files) - 3} more\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Events by Impact Strength:\")\n",
    "top_events = event_strength.head(5)\n",
    "for event, strength in top_events.items():\n",
    "    print(f\"  â€¢ {event}: {strength:.2f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Key Indicators by Sensitivity:\")\n",
    "top_indicators = indicator_sensitivity.head(5)\n",
    "for indicator, sensitivity in top_indicators.items():\n",
    "    print(f\"  â€¢ {indicator}: {sensitivity:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
