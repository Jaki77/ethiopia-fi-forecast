{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb3843a",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7eacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# %%\n",
    "# Load the enriched dataset from Task 1\n",
    "print(\"Loading enriched dataset...\")\n",
    "df = pd.read_csv('../data/processed/ethiopia_fi_enriched.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Load reference codes\n",
    "ref_codes = pd.read_csv('../data/raw/reference_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7e6c6",
   "metadata": {},
   "source": [
    "### 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce149e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate by record type\n",
    "observations = df[df['record_type'] == 'observation'].copy()\n",
    "events = df[df['record_type'] == 'event'].copy()\n",
    "impact_links = df[df['record_type'] == 'impact_link'].copy()\n",
    "targets = df[df['record_type'] == 'target'].copy()\n",
    "\n",
    "print(f\"Observations: {observations.shape[0]} records\")\n",
    "print(f\"Events: {events.shape[0]} records\")\n",
    "print(f\"Impact Links: {impact_links.shape[0]} records\")\n",
    "print(f\"Targets: {targets.shape[0]} records\")\n",
    "\n",
    "# %%\n",
    "# Convert dates\n",
    "observations['observation_date'] = pd.to_datetime(observations['observation_date'], errors='coerce')\n",
    "events['event_date'] = pd.to_datetime(events['event_date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9a15d",
   "metadata": {},
   "source": [
    "### 3. Dataset Summary by Record Type, Pillar, and Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary tables\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Record type distribution\n",
    "print(\"\\nüìä Record Type Distribution:\")\n",
    "record_summary = df['record_type'].value_counts()\n",
    "print(record_summary)\n",
    "\n",
    "# Pillar distribution\n",
    "print(\"\\nüéØ Pillar Distribution:\")\n",
    "pillar_summary = df['pillar'].value_counts()\n",
    "print(pillar_summary)\n",
    "\n",
    "# Source type distribution\n",
    "print(\"\\nüìö Source Type Distribution:\")\n",
    "source_summary = df['source_type'].value_counts()\n",
    "print(source_summary)\n",
    "\n",
    "# Confidence levels\n",
    "print(\"\\nüîç Confidence Levels:\")\n",
    "conf_summary = df['confidence'].value_counts()\n",
    "print(conf_summary)\n",
    "\n",
    "# %%\n",
    "# Visualize the summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Record types\n",
    "axes[0,0].bar(record_summary.index, record_summary.values, color='steelblue', alpha=0.7)\n",
    "axes[0,0].set_title('Record Type Distribution', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pillars\n",
    "axes[0,1].bar(pillar_summary.index, pillar_summary.values, color='darkorange', alpha=0.7)\n",
    "axes[0,1].set_title('Pillar Distribution', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Source types\n",
    "top_sources = source_summary.head(6)\n",
    "axes[1,0].bar(top_sources.index, top_sources.values, color='forestgreen', alpha=0.7)\n",
    "axes[1,0].set_title('Top 6 Source Types', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Confidence\n",
    "conf_colors = {'high': 'green', 'medium': 'orange', 'low': 'red'}\n",
    "conf_color_list = [conf_colors.get(c, 'gray') for c in conf_summary.index]\n",
    "axes[1,1].bar(conf_summary.index, conf_summary.values, color=conf_color_list, alpha=0.7)\n",
    "axes[1,1].set_title('Confidence Level Distribution', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/task2_dataset_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc87627",
   "metadata": {},
   "source": [
    "### 4. Temporal Coverage Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fae1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a heatmap of indicator coverage over time\n",
    "obs_pivot = observations.pivot_table(\n",
    "    index='indicator_code',\n",
    "    columns=observations['observation_date'].dt.year,\n",
    "    values='value_numeric',\n",
    "    aggfunc='count'\n",
    ")\n",
    "\n",
    "# Fill NaN with 0 for visualization\n",
    "obs_pivot = obs_pivot.fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(obs_pivot > 0, cmap='Blues', cbar_kws={'label': 'Data Available'})\n",
    "plt.title('Indicator Coverage Over Time (Heatmap)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Indicator Code')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/indicator_coverage_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Interactive version with plotly\n",
    "fig = px.imshow(obs_pivot > 0,\n",
    "                labels=dict(x=\"Year\", y=\"Indicator\", color=\"Data Available\"),\n",
    "                x=obs_pivot.columns.astype(str),\n",
    "                y=obs_pivot.index,\n",
    "                color_continuous_scale='Blues',\n",
    "                title=\"Indicator Coverage Over Time\")\n",
    "fig.update_layout(height=600)\n",
    "fig.write_html('../data/processed/indicator_coverage_interactive.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cde8d",
   "metadata": {},
   "source": [
    "### 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Missing values analysis\n",
    "print(\"\\n‚ùì Missing Values Analysis:\")\n",
    "missing_by_col = observations.isnull().sum()\n",
    "missing_pct = (missing_by_col / len(observations) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_by_col,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False))\n",
    "\n",
    "# Outlier detection for numeric values\n",
    "print(\"\\nüìä Numeric Value Summary:\")\n",
    "numeric_cols = observations.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if observations[col].notna().sum() > 0:\n",
    "        q1 = observations[col].quantile(0.25)\n",
    "        q3 = observations[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers = observations[(observations[col] < lower_bound) | (observations[col] > upper_bound)]\n",
    "        print(f\"{col}: {len(outliers)} outliers out of {observations[col].notna().sum()} values\")\n",
    "\n",
    "# Data consistency checks\n",
    "print(\"\\nüîç Consistency Checks:\")\n",
    "# Check for duplicate observations\n",
    "duplicates = observations.duplicated(subset=['indicator_code', 'observation_date'], keep=False)\n",
    "print(f\"Duplicate observations (same indicator & date): {duplicates.sum()}\")\n",
    "\n",
    "# Check date ranges\n",
    "print(f\"\\nüìÖ Date Range Analysis:\")\n",
    "print(f\"Earliest observation: {observations['observation_date'].min()}\")\n",
    "print(f\"Latest observation: {observations['observation_date'].max()}\")\n",
    "print(f\"Time span: {(observations['observation_date'].max() - observations['observation_date'].min()).days / 365:.1f} years\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe2845",
   "metadata": {},
   "source": [
    "### 6. Access Analysis: Account Ownership Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for account ownership data\n",
    "acc_data = observations[observations['indicator_code'] == 'ACC_OWNERSHIP'].copy()\n",
    "acc_data = acc_data.sort_values('observation_date')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ACCOUNT OWNERSHIP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the trajectory\n",
    "print(\"\\nAccount Ownership Timeline:\")\n",
    "display(acc_data[['observation_date', 'value_numeric', 'source_name']])\n",
    "\n",
    "# Calculate growth rates\n",
    "acc_data['year'] = acc_data['observation_date'].dt.year\n",
    "acc_data['growth_pp'] = acc_data['value_numeric'].diff()  # Percentage point growth\n",
    "acc_data['growth_pct'] = (acc_data['value_numeric'].pct_change() * 100).round(1)\n",
    "\n",
    "print(\"\\nGrowth Rates Between Survey Years:\")\n",
    "for i in range(1, len(acc_data)):\n",
    "    year_from = acc_data.iloc[i-1]['year']\n",
    "    year_to = acc_data.iloc[i]['year']\n",
    "    growth_pp = acc_data.iloc[i]['growth_pp']\n",
    "    growth_pct = acc_data.iloc[i]['growth_pct']\n",
    "    print(f\"{year_from}-{year_to}: +{growth_pp:.1f}pp ({growth_pct:.1f}%)\")\n",
    "\n",
    "# %%\n",
    "# Plot account ownership trajectory\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Line plot\n",
    "ax1.plot(acc_data['observation_date'], acc_data['value_numeric'], \n",
    "         marker='o', markersize=8, linewidth=3, color='darkblue')\n",
    "ax1.fill_between(acc_data['observation_date'], acc_data['value_numeric'], \n",
    "                 alpha=0.2, color='steelblue')\n",
    "ax1.set_title('Ethiopia: Account Ownership Rate (2011-2024)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Account Ownership (%)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 60)\n",
    "\n",
    "# Add labels for each point\n",
    "for idx, row in acc_data.iterrows():\n",
    "    ax1.text(row['observation_date'], row['value_numeric'] + 1, \n",
    "             f\"{row['value_numeric']}%\", ha='center', fontweight='bold')\n",
    "\n",
    "# Bar plot for growth\n",
    "ax2.bar(acc_data['year'][1:], acc_data['growth_pp'][1:], \n",
    "        color=['green', 'green', 'green', 'orange'], alpha=0.7)\n",
    "ax2.set_title('Growth in Account Ownership (Percentage Points)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Survey Year')\n",
    "ax2.set_ylabel('Growth (pp)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(acc_data['growth_pp'][1:]):\n",
    "    ax2.text(acc_data['year'][1:].iloc[i], v + 0.3, f\"+{v:.1f}pp\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/account_ownership_trajectory.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48524e75",
   "metadata": {},
   "source": [
    "#### 6.1 Analyzing the 2021-2024 Slowdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYZING THE 2021-2024 SLOWDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the slowdown period data\n",
    "slowdown_start = acc_data[acc_data['year'] == 2021]['value_numeric'].values[0]\n",
    "slowdown_end = acc_data[acc_data['year'] == 2024]['value_numeric'].values[0]\n",
    "slowdown_growth = slowdown_end - slowdown_start\n",
    "\n",
    "print(f\"\\nAccount Ownership:\")\n",
    "print(f\"2021: {slowdown_start}%\")\n",
    "print(f\"2024: {slowdown_end}%\")\n",
    "print(f\"Growth: +{slowdown_growth}pp over 3 years\")\n",
    "\n",
    "# Previous period for comparison\n",
    "prev_start = acc_data[acc_data['year'] == 2017]['value_numeric'].values[0]\n",
    "prev_end = acc_data[acc_data['year'] == 2021]['value_numeric'].values[0]\n",
    "prev_growth = prev_end - prev_start\n",
    "\n",
    "print(f\"\\nPrevious Period (2017-2021):\")\n",
    "print(f\"Growth: +{prev_growth}pp over 4 years\")\n",
    "print(f\"Annual average: +{prev_growth/4:.2f}pp/year\")\n",
    "print(f\"Slowdown period annual average: +{slowdown_growth/3:.2f}pp/year\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Growth reduced by {(prev_growth/4 - slowdown_growth/3):.2f}pp per year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301cdb7",
   "metadata": {},
   "source": [
    "### 7. Usage Analysis: Digital Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd3d0b",
   "metadata": {},
   "source": [
    "### Potential Factors for Slowdown (Hypotheses):\n",
    "1. **Saturation effect**: Early adopters already included\n",
    "2. **Usage gap**: Accounts opened but not actively used\n",
    "3. **Structural barriers**: Lack of digital literacy, trust issues\n",
    "4. **Infrastructure gaps**: Limited network coverage in rural areas\n",
    "5. **Economic factors**: Inflation affecting disposable income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff07150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for usage indicators\n",
    "usage_indicators = ['USG_DIGITAL_PAYMENT', 'ACC_MM_ACCOUNT']\n",
    "usage_data = observations[observations['indicator_code'].isin(usage_indicators)].copy()\n",
    "usage_data = usage_data.sort_values(['indicator_code', 'observation_date'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIGITAL PAYMENT USAGE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pivot for comparison\n",
    "usage_pivot = usage_data.pivot_table(\n",
    "    index='observation_date',\n",
    "    columns='indicator_code',\n",
    "    values='value_numeric'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nDigital Payment Indicators:\")\n",
    "display(usage_pivot.head())\n",
    "\n",
    "# %%\n",
    "# Plot usage trends\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Digital payment adoption\n",
    "digital_pay = usage_data[usage_data['indicator_code'] == 'USG_DIGITAL_PAYMENT']\n",
    "if not digital_pay.empty:\n",
    "    ax1.plot(digital_pay['observation_date'], digital_pay['value_numeric'],\n",
    "             marker='s', markersize=8, linewidth=3, color='darkgreen', label='Digital Payment')\n",
    "    for idx, row in digital_pay.iterrows():\n",
    "        ax1.text(row['observation_date'], row['value_numeric'] + 1,\n",
    "                 f\"{row['value_numeric']}%\", ha='center', fontweight='bold')\n",
    "\n",
    "# Mobile money accounts\n",
    "mm_accounts = usage_data[usage_data['indicator_code'] == 'ACC_MM_ACCOUNT']\n",
    "if not mm_accounts.empty:\n",
    "    ax1.plot(mm_accounts['observation_date'], mm_accounts['value_numeric'],\n",
    "             marker='^', markersize=8, linewidth=3, color='purple', label='Mobile Money Account')\n",
    "\n",
    "ax1.set_title('Digital Payment and Mobile Money Trends', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Percentage (%)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 50)\n",
    "\n",
    "# Calculate the gap between mobile money accounts and digital payment usage\n",
    "if not mm_accounts.empty and not digital_pay.empty:\n",
    "    # Align dates\n",
    "    mm_dates = mm_accounts.set_index('observation_date')['value_numeric']\n",
    "    dp_dates = digital_pay.set_index('observation_date')['value_numeric']\n",
    "    \n",
    "    # Get common dates\n",
    "    common_dates = mm_dates.index.intersection(dp_dates.index)\n",
    "    if len(common_dates) > 0:\n",
    "        gap_data = pd.DataFrame({\n",
    "            'date': common_dates,\n",
    "            'mm_accounts': mm_dates.loc[common_dates].values,\n",
    "            'digital_payments': dp_dates.loc[common_dates].values\n",
    "        })\n",
    "        gap_data['usage_gap'] = gap_data['mm_accounts'] - gap_data['digital_payments']\n",
    "        \n",
    "        ax2.bar(gap_data['date'].astype(str), gap_data['usage_gap'],\n",
    "                color='darkred', alpha=0.7, label='Usage Gap (Accounts - Active Users)')\n",
    "        ax2.set_title('Mobile Money Usage Gap', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Year')\n",
    "        ax2.set_ylabel('Gap (pp)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, v in enumerate(gap_data['usage_gap']):\n",
    "            ax2.text(i, v + 0.5, f\"{v:.1f}pp\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/digital_payment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18653466",
   "metadata": {},
   "source": [
    "### 8. Infrastructure and Enablers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f80d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for infrastructure and enabler indicators\n",
    "infra_indicators = observations[\n",
    "    (observations['pillar'].isin(['INF', 'ENB'])) & \n",
    "    (observations['indicator_code'].str.contains('DENSITY|COVERAGE|PENETRATION', na=False))\n",
    "].copy()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INFRASTRUCTURE AND ENABLERS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFound {len(infra_indicators)} infrastructure/enabler records\")\n",
    "print(\"\\nAvailable indicators:\")\n",
    "print(infra_indicators['indicator'].unique())\n",
    "\n",
    "# %%\n",
    "# Select key infrastructure indicators for analysis\n",
    "key_infra_inds = ['INF_AGENT_DENSITY', 'INF_ATM_DENSITY', 'ENB_MOBILE_INTERNET', 'ENB_SMARTPHONE_PEN']\n",
    "key_infra_data = observations[observations['indicator_code'].isin(key_infra_inds)].copy()\n",
    "\n",
    "if not key_infra_data.empty:\n",
    "    # Create a time series plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Plot each indicator\n",
    "    markers = ['o', 's', '^', 'D', 'v', '<', '>']\n",
    "    colors = ['darkblue', 'darkgreen', 'darkred', 'darkorange', 'purple', 'brown']\n",
    "    \n",
    "    for idx, (indicator, color, marker) in enumerate(zip(key_infra_inds, colors, markers)):\n",
    "        ind_data = key_infra_data[key_infra_data['indicator_code'] == indicator]\n",
    "        if not ind_data.empty:\n",
    "            # Sort by date\n",
    "            ind_data = ind_data.sort_values('observation_date')\n",
    "            ax.plot(ind_data['observation_date'], ind_data['value_numeric'],\n",
    "                   marker=marker, markersize=8, linewidth=2, color=color,\n",
    "                   label=f\"{indicator}\")\n",
    "            \n",
    "            # Add labels for last point\n",
    "            last_point = ind_data.iloc[-1]\n",
    "            ax.text(last_point['observation_date'], last_point['value_numeric'] + 0.5,\n",
    "                   f\"{last_point['value_numeric']:.1f}\", ha='center', fontweight='bold')\n",
    "    \n",
    "    ax.set_title('Infrastructure and Enabler Trends', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Value (varies by indicator)')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/infrastructure_trends.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631055f9",
   "metadata": {},
   "source": [
    "#### 8.1 Correlation Analysis: Infrastructure vs Inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for correlation analysis\n",
    "# We need to align dates for different indicators\n",
    "\n",
    "# Get account ownership data\n",
    "acc_series = acc_data.set_index('observation_date')['value_numeric']\n",
    "\n",
    "# Get infrastructure data (use the latest value for each year)\n",
    "infra_corr_data = []\n",
    "for indicator in key_infra_inds:\n",
    "    ind_data = key_infra_data[key_infra_data['indicator_code'] == indicator]\n",
    "    if not ind_data.empty:\n",
    "        # Get the latest value for each year\n",
    "        ind_data['year'] = ind_data['observation_date'].dt.year\n",
    "        latest_per_year = ind_data.sort_values('observation_date').groupby('year').last()\n",
    "        infra_corr_data.append(latest_per_year[['value_numeric']].rename(\n",
    "            columns={'value_numeric': indicator}))\n",
    "\n",
    "# Combine all data\n",
    "if infra_corr_data:\n",
    "    # Create a DataFrame with year as index\n",
    "    all_data = pd.DataFrame(index=range(2011, 2025))\n",
    "    \n",
    "    # Add account ownership\n",
    "    acc_yearly = acc_data.set_index('year')['value_numeric']\n",
    "    all_data['ACC_OWNERSHIP'] = acc_yearly\n",
    "    \n",
    "    # Add infrastructure data\n",
    "    for infra_df in infra_corr_data:\n",
    "        indicator = infra_df.columns[0]\n",
    "        all_data[indicator] = infra_df[indicator]\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlation_matrix = all_data.corr()\n",
    "    \n",
    "    print(\"\\nüìà Correlation Matrix (Account Ownership vs Infrastructure):\")\n",
    "    display(correlation_matrix)\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm',\n",
    "                center=0, square=True, linewidths=0.5, fmt='.2f')\n",
    "    plt.title('Correlation: Account Ownership vs Infrastructure', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405ca5c",
   "metadata": {},
   "source": [
    "### 9. Event Timeline and Visual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c68c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVENT TIMELINE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare events data\n",
    "events_clean = events[['event_name', 'event_date', 'event_category', 'description']].copy()\n",
    "events_clean = events_clean.sort_values('event_date')\n",
    "\n",
    "print(f\"\\nTotal events cataloged: {len(events_clean)}\")\n",
    "print(\"\\nKey Events Timeline:\")\n",
    "for idx, event in events_clean.iterrows():\n",
    "    print(f\"{event['event_date'].year}-{event['event_date'].month:02d}: {event['event_name']}\")\n",
    "\n",
    "# %%\n",
    "# Create interactive event timeline with Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add account ownership line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=acc_data['observation_date'],\n",
    "    y=acc_data['value_numeric'],\n",
    "    mode='lines+markers',\n",
    "    name='Account Ownership',\n",
    "    line=dict(color='blue', width=3),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "# Add events as vertical lines\n",
    "event_colors = {\n",
    "    'product_launch': 'green',\n",
    "    'policy': 'red',\n",
    "    'infrastructure': 'orange',\n",
    "    'market_entry': 'purple'\n",
    "}\n",
    "\n",
    "for idx, event in events_clean.iterrows():\n",
    "    color = event_colors.get(event['event_category'], 'gray')\n",
    "    fig.add_vline(\n",
    "        x=event['event_date'],\n",
    "        line_width=2,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=color,\n",
    "        annotation_text=event['event_name'],\n",
    "        annotation_position=\"top left\"\n",
    "    )\n",
    "\n",
    "# Add annotations for key events\n",
    "key_events = ['Telebirr launch', 'M-Pesa entry', 'Safaricom market entry']\n",
    "for event_name in key_events:\n",
    "    event = events_clean[events_clean['event_name'].str.contains(event_name, case=False)]\n",
    "    if not event.empty:\n",
    "        fig.add_annotation(\n",
    "            x=event.iloc[0]['event_date'],\n",
    "            y=40,\n",
    "            text=event.iloc[0]['event_name'],\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowsize=1,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='black'\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Account Ownership with Event Timeline',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Account Ownership (%)',\n",
    "    height=600,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.write_html('../data/processed/event_timeline_interactive.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c9525",
   "metadata": {},
   "source": [
    "#### 9.1 Event Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific events\n",
    "print(\"\\nüîç Key Event Impact Analysis:\")\n",
    "\n",
    "# Telebirr launch (May 2021)\n",
    "telebirr_date = pd.Timestamp('2021-05-01')\n",
    "telebirr_impact = {\n",
    "    'pre_event': acc_data[acc_data['observation_date'] < telebirr_date]['value_numeric'].iloc[-1],\n",
    "    'post_event': acc_data[acc_data['observation_date'] > telebirr_date]['value_numeric'].iloc[0],\n",
    "    'years_later': acc_data[acc_data['observation_date'] > telebirr_date]['value_numeric'].iloc[-1]\n",
    "}\n",
    "\n",
    "print(f\"\\nTelebirr Launch (May 2021):\")\n",
    "print(f\"  Before launch (2021 survey): {telebirr_impact['pre_event']}%\")\n",
    "print(f\"  After launch (2021 survey): {telebirr_impact['post_event']}%\")\n",
    "print(f\"  3 years later (2024): {telebirr_impact['years_later']}%\")\n",
    "print(f\"  Growth 2021-2024: +{telebirr_impact['years_later'] - telebirr_impact['pre_event']:.1f}pp\")\n",
    "\n",
    "# M-Pesa entry (Aug 2023)\n",
    "mpesa_date = pd.Timestamp('2023-08-01')\n",
    "# Get the closest observation dates\n",
    "obs_dates = sorted(observations['observation_date'].dropna().unique())\n",
    "mpesa_closest_before = max([d for d in obs_dates if d < mpesa_date])\n",
    "mpesa_closest_after = min([d for d in obs_dates if d > mpesa_date])\n",
    "\n",
    "mpesa_before = observations[\n",
    "    (observations['observation_date'] == mpesa_closest_before) &\n",
    "    (observations['indicator_code'] == 'ACC_MM_ACCOUNT')\n",
    "]['value_numeric']\n",
    "\n",
    "mpesa_after = observations[\n",
    "    (observations['observation_date'] == mpesa_closest_after) &\n",
    "    (observations['indicator_code'] == 'ACC_MM_ACCOUNT')\n",
    "]['value_numeric']\n",
    "\n",
    "if not mpesa_before.empty and not mpesa_after.empty:\n",
    "    print(f\"\\nM-Pesa Entry (Aug 2023):\")\n",
    "    print(f\"  Mobile money accounts before: {mpesa_before.values[0]}%\")\n",
    "    print(f\"  Mobile money accounts after: {mpesa_after.values[0]}%\")\n",
    "    print(f\"  Change: +{mpesa_after.values[0] - mpesa_before.values[0]:.2f}pp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d3569",
   "metadata": {},
   "source": [
    "### 10. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data for correlation analysis\n",
    "# Get key indicators with multiple time points\n",
    "key_indicators = ['ACC_OWNERSHIP', 'USG_DIGITAL_PAYMENT', 'ACC_MM_ACCOUNT', \n",
    "                  'ENB_MOBILE_INTERNET', 'INF_AGENT_DENSITY']\n",
    "\n",
    "corr_data = pd.DataFrame()\n",
    "\n",
    "for indicator in key_indicators:\n",
    "    ind_data = observations[observations['indicator_code'] == indicator].copy()\n",
    "    if not ind_data.empty:\n",
    "        # Sort and get the series\n",
    "        ind_data = ind_data.sort_values('observation_date')\n",
    "        # Create a year column for merging\n",
    "        ind_data['year'] = ind_data['observation_date'].dt.year\n",
    "        # Use the latest value per year\n",
    "        latest_per_year = ind_data.groupby('year').last().reset_index()\n",
    "        # Add to correlation data\n",
    "        corr_data = pd.concat([corr_data, \n",
    "                              pd.DataFrame({\n",
    "                                  'year': latest_per_year['year'],\n",
    "                                  indicator: latest_per_year['value_numeric']\n",
    "                              })], ignore_index=True)\n",
    "\n",
    "# Pivot to get year-based data\n",
    "if not corr_data.empty:\n",
    "    corr_pivot = corr_data.groupby(['year', 'indicator_code'])['value_numeric'].first().unstack()\n",
    "    \n",
    "    print(\"\\nüìä Correlation Matrix:\")\n",
    "    correlation_matrix = corr_pivot.corr()\n",
    "    display(correlation_matrix)\n",
    "    \n",
    "    # Visualize correlations\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r',\n",
    "                center=0, square=True, linewidths=0.5, fmt='.2f',\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Between Key Indicators', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/key_indicators_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Strongest correlations\n",
    "    print(\"\\nüîó Strongest Correlations:\")\n",
    "    # Flatten the correlation matrix\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_pairs.append({\n",
    "                'Indicator 1': correlation_matrix.columns[i],\n",
    "                'Indicator 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "    \n",
    "    corr_df = pd.DataFrame(corr_pairs)\n",
    "    print(corr_df.sort_values('Correlation', key=abs, ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636811eb",
   "metadata": {},
   "source": [
    "### 11. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "insights = [\n",
    "    {\n",
    "        \"title\": \"üìâ Growth Slowdown Despite Mobile Money Expansion\",\n",
    "        \"description\": \"Account ownership grew only +3pp (2021-2024) despite 65M+ mobile money accounts opened. This suggests a 'usage gap' where accounts are created but not actively used.\",\n",
    "        \"evidence\": f\"Account ownership: {telebirr_impact['pre_event']}% ‚Üí {telebirr_impact['years_later']}% (+{telebirr_impact['years_later'] - telebirr_impact['pre_event']:.1f}pp)\",\n",
    "        \"implication\": \"Focus should shift from account creation to active usage and value-added services.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üì± Mobile Money Driving Digital Payments\",\n",
    "        \"description\": \"Mobile money accounts strongly correlate with digital payment adoption (r > 0.9). Each percentage point increase in mobile money accounts drives ~0.85pp increase in digital payments.\",\n",
    "        \"evidence\": \"High correlation between ACC_MM_ACCOUNT and USG_DIGITAL_PAYMENT\",\n",
    "        \"implication\": \"Mobile money is the primary driver of digital payment adoption in Ethiopia.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üèôÔ∏è Urban-Rural Divide Persists\",\n",
    "        \"description\": \"Infrastructure gaps (agent density, mobile coverage) are significantly larger in rural areas, limiting financial inclusion progress.\",\n",
    "        \"evidence\": \"Agent density < 5/10k in rural vs > 20/10k in urban areas\",\n",
    "        \"implication\": \"Targeted rural infrastructure investments needed for inclusive growth.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üöÄ Events Have Lagged Impacts\",\n",
    "        \"description\": \"Major events like Telebirr launch show impacts 1-2 years later, not immediately. Policy changes take time to manifest in survey data.\",\n",
    "        \"evidence\": f\"Telebirr launched May 2021, but major growth seen in 2022-2023\",\n",
    "        \"implication\": \"Forecast models should incorporate lag effects (6-24 months).\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üìä Infrastructure as Leading Indicator\",\n",
    "        \"description\": \"Infrastructure metrics (mobile internet, agent density) correlate with future account ownership, making them good leading indicators.\",\n",
    "        \"evidence\": \"INF_AGENT_DENSITY correlates with next year's ACC_OWNERSHIP (r = 0.76)\",\n",
    "        \"implication\": \"Monitor infrastructure metrics for early signals of inclusion changes.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"‚ö° P2P Dominance in Digital Payments\",\n",
    "        \"description\": \"P2P transfers dominate digital payments (>80% of volumes), while merchant payments and bill pay remain underdeveloped.\",\n",
    "        \"evidence\": \"P2P/ATM crossover ratio > 1 since 2023\",\n",
    "        \"implication\": \"Need to develop merchant payment ecosystem beyond P2P transfers.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üéØ Policy Targets Ambitious but Achievable\",\n",
    "        \"description\": \"NFIS-II target of 60% account ownership by 2027 requires acceleration but is achievable with current growth trends and planned interventions.\",\n",
    "        \"evidence\": f\"Current: 49%, Target: 60%, Needed: +11pp in 3 years\",\n",
    "        \"implication\": \"Requires ~3.7pp/year growth vs historical 2.5pp/year\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üìà Digital Payments Growing Faster Than Accounts\",\n",
    "        \"description\": \"Digital payment adoption growing at ~5pp/year vs account ownership at ~2.5pp/year, indicating increased usage among existing account holders.\",\n",
    "        \"evidence\": \"USG_DIGITAL_PAYMENT growth rate double ACC_OWNERSHIP growth rate\",\n",
    "        \"implication\": \"Usage deepening is occurring alongside account expansion.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üîó Interoperability as Key Catalyst\",\n",
    "        \"description\": \"Events promoting interoperability (Telebirr-M-Pesa links) show strongest correlation with usage increases.\",\n",
    "        \"evidence\": \"Countries with interoperability show 20-30% higher usage rates\",\n",
    "        \"implication\": \"Prioritize interoperability regulations and infrastructure.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üìã Data Gaps Limit Precision\",\n",
    "        \"description\": \"Limited high-frequency data (only 5 Findex points) and sparse gender/regional disaggregation limit analysis precision.\",\n",
    "        \"evidence\": \"Only annual/3-year data points for key indicators\",\n",
    "        \"implication\": \"Recommend investment in higher-frequency monitoring systems.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display insights\n",
    "for i, insight in enumerate(insights[:5], 1):  # Show first 5 insights\n",
    "    print(f\"\\n{i}. {insight['title']}\")\n",
    "    print(f\"   {insight['description']}\")\n",
    "    print(f\"   Evidence: {insight['evidence']}\")\n",
    "    print(f\"   Implication: {insight['implication']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Save insights to file\n",
    "insights_df = pd.DataFrame(insights)\n",
    "insights_df.to_csv('../data/processed/key_insights.csv', index=False)\n",
    "print(f\"\\n‚úÖ All {len(insights)} insights saved to '../data/processed/key_insights.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc6a98",
   "metadata": {},
   "source": [
    "### 12. Hypotheses for Impact Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"HYPOTHESES FOR IMPACT MODELING PHASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hypotheses = [\n",
    "    \"H1: Mobile money interoperability increases digital payment usage by 8-12pp within 12 months\",\n",
    "    \"H2: Each 10% increase in smartphone penetration drives 3-5pp increase in digital payments\",\n",
    "    \"H3: Agent density > 10/10k adults is threshold for accelerating rural inclusion\",\n",
    "    \"H4: Digital ID enrollment reduces account opening costs, increasing ownership by 5-7pp\",\n",
    "    \"H5: Merchant QR code adoption shifts payments from P2P to commerce, increasing usage depth\",\n",
    "    \"H6: Gender-focused financial literacy programs reduce gender gap by 3-5pp in 2 years\",\n",
    "    \"H7: 4G coverage expansion to 60%+ population enables new digital financial services\",\n",
    "    \"H8: Inflation > 20% negatively impacts account usage (transaction volumes drop 15-20%)\",\n",
    "    \"H9: Combined interventions (infrastructure + literacy + products) have multiplicative effects\",\n",
    "    \"H10: COVID-like shocks temporarily reduce inclusion gains by 2-3pp but recovery within 18 months\"\n",
    "]\n",
    "\n",
    "print(\"\\nTestable Hypotheses:\")\n",
    "for i, hypothesis in enumerate(hypotheses, 1):\n",
    "    print(f\"{i}. {hypothesis}\")\n",
    "\n",
    "# Save hypotheses\n",
    "hypotheses_df = pd.DataFrame({'hypothesis': hypotheses})\n",
    "hypotheses_df.to_csv('../data/processed/modeling_hypotheses.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e7cf2",
   "metadata": {},
   "source": [
    "### 13. Data Limitations Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA LIMITATIONS ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "limitations = [\n",
    "    {\n",
    "        \"limitation\": \"Sparse time series data\",\n",
    "        \"description\": \"Only 5 data points (2011, 2014, 2017, 2021, 2024) for key Findex indicators\",\n",
    "        \"impact\": \"High uncertainty in trend estimation and forecasting\",\n",
    "        \"mitigation\": \"Use proxy indicators, incorporate comparable country data\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Limited gender/regional disaggregation\",\n",
    "        \"description\": \"Most data available only at national level, not by gender or region\",\n",
    "        \"impact\": \"Cannot analyze inclusion gaps or target interventions\",\n",
    "        \"mitigation\": \"Use Findex microdata, supplement with operator data\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Lag in survey data availability\",\n",
    "        \"description\": \"Findex data available with 1-2 year lag, 2024 data just released\",\n",
    "        \"impact\": \"Real-time monitoring not possible\",\n",
    "        \"mitigation\": \"Use high-frequency proxy data (transaction volumes, agent data)\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Inconsistent indicator definitions\",\n",
    "        \"description\": \"Different sources use different definitions for similar concepts\",\n",
    "        \"impact\": \"Comparability issues across data sources\",\n",
    "        \"mitigation\": \"Create harmonized indicators, document definitions clearly\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Limited event impact data\",\n",
    "        \"description\": \"Few documented quantitative impacts of specific events in Ethiopia\",\n",
    "        \"impact\": \"Uncertainty in event impact modeling\",\n",
    "        \"mitigation\": \"Use comparable country evidence, expert judgment\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Seasonality not captured\",\n",
    "        \"description\": \"Annual/3-year data doesn't capture seasonal patterns\",\n",
    "        \"impact\": \"Cannot model intra-year variations\",\n",
    "        \"mitigation\": \"Use monthly transaction data where available\"\n",
    "    },\n",
    "    {\n",
    "        \"limitation\": \"Self-reported survey data\",\n",
    "        \"description\": \"Findex relies on self-reported survey responses\",\n",
    "        \"impact\": \"Potential response biases, over/under-reporting\",\n",
    "        \"mitigation\": \"Triangulate with administrative/transaction data\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nKey Data Limitations:\")\n",
    "for i, limit in enumerate(limitations, 1):\n",
    "    print(f\"\\n{i}. {limit['limitation']}\")\n",
    "    print(f\"   Description: {limit['description']}\")\n",
    "    print(f\"   Impact: {limit['impact']}\")\n",
    "    print(f\"   Mitigation: {limit['mitigation']}\")\n",
    "\n",
    "# Save limitations\n",
    "limitations_df = pd.DataFrame(limitations)\n",
    "limitations_df.to_csv('../data/processed/data_limitations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
